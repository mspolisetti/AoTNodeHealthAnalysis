---
title: "Create Node - Sensor Status timelines for a given node"
author: "Madhavi Polisetti"
date: "01/06/2019"
output: pdf_document
---

```{r}

load.libraries = c('dplyr','lubridate',"visdat","reshape2","scales",'tidyverse','plyr','ggplot')
sapply(load.libraries, require, character = TRUE)
```

```{r}
# Read all Sensor information
inputfilename =  "sensors.csv" 
datapath = "Node-inputs"
sensor.list.main = read.csv(paste(datapath, inputfilename, sep = "/"), stringsAsFactors = FALSE)
nrow(sensor.list.main)

#Filter out list of sensors we care about -- All the "Sensing" sensors
sensor.list1 = filter(sensor.list.main, grepl("sensing", ontology, fixed = TRUE))
nrow(sensor.list1)

#Create a unique key to resperesent each sensor type-subsystem-parametere combination
sensor.list1$sensorkey <- paste(sensor.list1$subsystem , sensor.list1$sensor  , sensor.list1$parameter)
head(sensor.list1["sensorkey"])

#Pick the sensor columns we need
sensorcols = c("hrf_minval", "hrf_maxval", "sensorkey")
sensor.list = sensor.list1 %>% select(sensorcols)
```


```{r}

processNode = function(node.data) {

#Create a unique sensor key in the nodes dataset
node.data$sensorkey <-  paste(node.data$subsystem , node.data$sensor  , node.data$parameter)

# Define which columns to keep from the original data
colpick1 = c("timestamp", "node_id", "value_hrf", "sensorkey")

#Picking the node that the team is cross-checking with each other
node.data1 = node.data%>%  select(colpick1)  

#Drop rows with NA in the value_hrf column
#Filter only the sensors that we need (Sensor.list has the list of sensors we care about)
node.data.filtered = node.data1 %>%
  filter((c(node.data1$sensorkey) %in%sensor.list$sensorkey))%>%drop_na(value_hrf)

#Join with sensor.list dataframe to bring back columns hrf_min hrf_max
node.data.joined = merge(x = node.data.filtered, y = sensor.list, by = "sensorkey", all.x = TRUE)
node.data.joined$value_hrf = as.numeric(node.data.joined$value_hrf)

# Create indicator "WithinBounds" to indicate if each individual readings is within specified bounds for the sensor
node.data.joined = node.data.joined %>% 
  mutate(withinBounds = ((value_hrf - hrf_minval) > 0 | is.na(hrf_minval)) 
         #within Lower bound or Lower Bound spaces``
                        & ((hrf_maxval - value_hrf) > 0) | is.na(hrf_maxval))
         #within Upper bound or Upper Bound spaces

# Generate the list of dataframes for each sensor, parameter, and subsystem  
node.sensor = split(node.data.joined, with(node.data.joined, interaction(sensorkey)), drop = TRUE)

# Keep only Timestamp and Sensor readings
node.sensor.reduce = lapply(node.sensor, function(x) x[(names(x) %in% c("timestamp", "value_hrf",'withinBounds'))])

# Use the defined functions above to calculate the average, min and max values over the period
node.sensor.aggregated = lapply(node.sensor.reduce, AggredateData)

#Final dataframe - Keep only the labels needed
node.sensor.final = lapply(node.sensor.aggregated, function(x) x[(names(x) %in% c("dateday",   "sensorStatus"))])

# Rename the columns for each dataframe inside the list
# so that dateday is the timestamp and the the sensorStatus is in the format of (sensor name).(parameter name).(subsystem name)

node.sensor.final.renamed = lapply(names(node.sensor.final), 
                            function(x) setNames(node.sensor.final[[x]], c(names(node.sensor.final[[x]])[1], x)))

#Final merged dataframe with sensor-wise-Status for each day
node.sensor.final.merged = purrr::reduce(node.sensor.final.renamed, left_join, by = "dateday")

return(node.sensor.final.merged)
}
```


```{r}

# Define function to calculate average value, maximum and minimum over a certian time interval
# Default is over 1 day
AggredateData = function(data, timeslot = "1 day") {
   
  data$timestamp = ymd_hms(data$timestamp)
  
  data$dateday = cut(data$timestamp, breaks =  timeslot)
  
   aggrData = data %>% 
    mutate(dateday = floor_date(timestamp, unit=timeslot)) %>% 
    group_by(dateday) %>% 
    dplyr::summarize(
       maxReadingForTimePeriod = max(value_hrf,na.rm = TRUE)
     , minReadingForTimePeriod = min(value_hrf,na.rm = TRUE)
     , flatlined = (max(value_hrf,na.rm = TRUE) - min(value_hrf,na.rm = TRUE) == 0)
     , CntOutOfBounds = sum(withinBounds == FALSE)
     , CntWithinBounds = sum(withinBounds == TRUE)
     , TotalReadingsForTimePeriod = n()
     , WithinBounds = (sum(withinBounds == TRUE) > 0)
     , sensorStatus = case_when(
      (max(value_hrf) - min(value_hrf) < min(value_hrf) * 0) & (sum(withinBounds == TRUE) <= sum (withinBounds == withinBounds) * 0) ~ 3, 
      (max(value_hrf) - min(value_hrf) <= min(value_hrf) * 0) ~ 1, 
      (sum(withinBounds == TRUE) <= sum(withinBounds == withinBounds) * 0) ~ 2, 
      TRUE ~ 0)) 
   
  return(aggrData)
}

```

```{r}
createVis = function(df, nodeid) {
  #color scale
  col<-c("grey","green","yellow","orange","red")
  
  #convert dataframe to column-wise datafram
  data.m <- melt(df, id ="dateday" )
  
  
  #the ggplot
    p<-ggplot(data.m,aes(x=variable,y=dateday))+
    #tile layer
    geom_tile( size=0.1,aes(fill=factor(value))) +
 
  labs(x="",y="")+
    #setting the color
    scale_fill_manual(expand=c(0,0),
        values=c("palegreen","yellow","orange","palered"),
        breaks=c(NA, 0, 1, 2, 3),
        labels=c("Missing","Normal", "Flatlined", "OutOfBounds", "AbNormal"),
        name = paste( " Visualization for NODE: ", nodeid , sep="")
        ) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  
  theme(
#bold font for both axis text
axis.text=element_text(face="bold"),
#set thickness of axis ticks
axis.ticks=element_line(size=0.4),
#remove plot background
plot.background=element_blank(),
#remove plot border
panel.border=element_blank())
    
datapath2 = "Node-outputs"
filename = paste("node_" , nodeid , "heatmap.png", sep = "")
    
 ggsave(filename=paste(datapath2, filename, sep = "/"),plot = p,dpi=150,type="cairo")

}
```


```{r}
writeNodeWiseData = function(node.data) {
  
# Define columns to keep from the original weekly node readings data
colpick = c("timestamp", "node_id", "value_hrf", "sensor", "parameter", "subsystem")

df = processNode(node.data)

date.seq = data.frame(seq(as.Date("2018/1/1"), as.Date("2018/12/31"), "days"))
colnames(date.seq) = 'dateday'

df$dateday = ymd(df$dateday)

final.df = merge(date.seq, df, by='dateday', all.x=TRUE)
 
View(final.df)

return (final.df)
}

```



```{r}
createNodeFindings = function( nodeid) {
  inputfilename = paste("node-" , nodeid , ".csv", sep = "")
  datapath = "Node-inputs"

  datapath2 = "Node-outputs"
  node.1 = read.csv(paste(datapath, inputfilename, sep = "/"), stringsAsFactors = FALSE)
  
  node.OP <-  writeNodeWiseData(node.1)
  createVis(node.OP, nodeid)
  
  filename = paste("node_" , nodeid , "_Output.csv", sep = "")
  write.csv(node.OP, file = paste(datapath2, filename, sep = "/"), row.names = FALSE)
  
  return (node.OP)
}
```

```{r}
#Main execution
#Everything else is a function

#Set node_id for which we need Visualization
#nodeid="001e0610ee33"
nodeid = '001e0610ee33'
 
#Setup two folders in the working directory : Node-outputs & Node-inputs.
#Name the inputfile node-nodeid.csv

#Process below will writeout 
#       1. A csv file indicating various sensor statuses.
#       2. heatmap for Sensor functiioning named heatmap.png
node.OP = createNodeFindings(nodeid)


```





 